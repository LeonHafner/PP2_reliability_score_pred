{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f480aeba-7427-476c-88c7-5208ef114a4c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.66.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.11.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
      "Collecting jax\n",
      "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
      "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax)\n",
      "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
      "Collecting ml-dtypes>=0.4.0 (from jax)\n",
      "  Downloading ml_dtypes-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax) (3.3.0)\n",
      "Downloading jax-0.4.35-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl (87.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.3/87.3 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m131.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ml-dtypes, jaxlib, jax\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.2.0\n",
      "    Uninstalling ml-dtypes-0.2.0:\n",
      "      Successfully uninstalled ml-dtypes-0.2.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.15.0 requires ml-dtypes~=0.2.0, but you have ml-dtypes 0.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jax-0.4.35 jaxlib-0.4.35 ml-dtypes-0.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tqdm scipy numpy jax h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839a0573-ace1-4e0d-aa6d-075d42ceda19",
   "metadata": {},
   "source": [
    "Code adapted from: https://github.com/zzhangzzhang/pLMs-interpretability/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e107018c-886c-432a-8d83-80923043f6b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os \n",
    "import torch \n",
    "import json \n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from utils import *\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c36c903-4bd3-4854-a953-0d35eec425f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Record GPU needed and time for processing one jacobian Matrix\n",
    "# Save jacobian Matrix/contact map\n",
    "def get_categorical_jacobian(seq, alphabet, model):\n",
    "  # ∂in/∂out\n",
    "  x,ln = alphabet.get_batch_converter()([(\"seq\",seq)])[-1],len(seq)\n",
    "  with torch.no_grad():\n",
    "    f = lambda x: model(x)[\"logits\"][...,1:(ln+1),4:24].cpu().numpy()\n",
    "    fx = f(x.to(device))[0]\n",
    "    x = torch.tile(x,[20,1]).to(device)\n",
    "    fx_h = np.zeros((ln,20,ln,20))\n",
    "    for n in range(ln): # for each position\n",
    "      x_h = torch.clone(x)\n",
    "      x_h[:,n+1] = torch.arange(4,24) # mutate to all 20 aa\n",
    "      fx_h[n] = f(x_h)\n",
    "    return fx_h - fx\n",
    "def get_contacts(x, symm=True, center=True, rm=1):\n",
    "  # convert jacobian (L,A,L,A) to contact map (L,L)\n",
    "  j = x.copy()\n",
    "  if center:\n",
    "    for i in range(4): j -= j.mean(i,keepdims=True)\n",
    "  j_fn = np.sqrt(np.square(j).sum((1,3)))\n",
    "  np.fill_diagonal(j_fn,0)\n",
    "  j_fn_corrected = do_apc(j_fn, rm=rm)\n",
    "  if symm:\n",
    "    j_fn_corrected = (j_fn_corrected + j_fn_corrected.T)/2\n",
    "  return j_fn_corrected\n",
    "def do_apc(x, rm=1):\n",
    "  '''given matrix do apc correction'''\n",
    "  # trying to remove different number of components\n",
    "  # rm=0 remove none\n",
    "  # rm=1 apc\n",
    "  x = np.copy(x)\n",
    "  if rm == 0:\n",
    "    return x\n",
    "  elif rm == 1:\n",
    "    a1 = x.sum(0,keepdims=True)\n",
    "    a2 = x.sum(1,keepdims=True)\n",
    "    y = x - (a1*a2)/x.sum()\n",
    "  else:\n",
    "    # decompose matrix, rm largest(s) eigenvectors\n",
    "    u,s,v = np.linalg.svd(x)\n",
    "    y = s[rm:] * u[:,rm:] @ v[rm:,:]\n",
    "  np.fill_diagonal(y,0)\n",
    "  return y\n",
    "def do_model_run(model_name, sequence, pid):\n",
    "    # LOAD MODEL AND PUT TO GPU / Validation: higher similiarity ok: 50%\n",
    "    model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", model_name)\n",
    "    # put model on GPU if available\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2'\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    #model.args.token_dropout = False\n",
    "    \n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    print(f\"starting {pid}_{model_name}\")\n",
    "    cjm = get_categorical_jacobian(sequence, alphabet, model)\n",
    "    contact_map = get_contacts(cjm)\n",
    "    \n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"{pid}_{model_name} took {elapsed_time} seconds\")\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(contact_map, cmap=\"viridis\", interpolation=\"nearest\")\n",
    "    plt.colorbar(label=\"Contact Strength\")\n",
    "    plt.title(f\"{model_name} {pid} Contact Map Heatmap\")\n",
    "    plt.xlabel(\"Position\")\n",
    "    plt.ylabel(\"Position\")\n",
    "    plt.savefig(f\"out/{pid}_{model_name}_contact_map.png\")\n",
    "    \n",
    "    plt.clf()\n",
    "    \n",
    "    # Save the result\n",
    "    with h5py.File(f'out/{pid}_{model_name}.h5', 'w') as f:\n",
    "        f.create_dataset(pid, data=contact_map)\n",
    "    print(f\"finished {pid}_{model_name}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111814eb-bd39-4329-b182-b496836cf405",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/cw_liao/.cache/torch/hub/facebookresearch_esm_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1TX4-A_esm2_t33_650M_UR50D took 1233.877678155899 seconds\n",
      "finished 1TX4-A_esm2_t33_650M_UR50D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pid = \"3LAEA\"\n",
    "pid3 = \"1TX4-A\"\n",
    "# sequence = \"SNAIQQSDGSMIIDGSANLRDLNKMFNWELDTEDARTFNGLILEHLEEIPDEGTICEIDGLLITILEVGDNMIKQAKVVKL\"\n",
    "# sequence2 = \"RPPLPNQQFGVSLQHLQEKNPEQEPIPIVLRETVAYLQAHALTTEGIFRRSANTQVVREVQQKYNMGLPVDFDQYNALHLPAVILKTFLRELPEPLLTFDLYPHVVGFLNIDESQRVPATLQVLQTLPEENYQVLRFLTAFLVQISAHSDQNKMTNTNLAVVFGPNLLWAKDAAITLKAINPINTFTKFLLDHQGELF\"\n",
    "sequence3 = \"PLPNQQFGVSLQHLQEKNPEQEPIPIVLRETVAYLQAHALTTEGIFRRSANTQVVREVQQKYNMGLPVDFDQYNALHLPAVILKTFLRELPEPLLTFDLYPHVVGFLNIDESQRVPATLQVLQTLPEENYQVLRFLTAFLVQISAHSDQNKMTNTNLAVVFGPNLLWAKDAAITLKAINPINTFTKFLLDHQGELF\"\n",
    "print(len(sequence3))\n",
    "# model_names = [\"esm2_t6_8M_UR50D\", \"esm2_t12_35M_UR50D\", \"esm2_t30_150M_UR50D\", \"esm2_t33_650M_UR50D\", \"esm2_t36_3B_UR50D\"]\n",
    "model_names = [\"esm2_t33_650M_UR50D\"]\n",
    "\n",
    "for model_name in model_names:\n",
    "    do_model_run(model_name, sequence3, pid3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c211b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
